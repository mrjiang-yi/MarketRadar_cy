import os
import pandas as pd
import akshare as ak
import yfinance as yf
import requests
import random
import time
import socket
import numpy as np # MyTT éœ€è¦ numpy
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError

import utils

# === å°è¯•å¯¼å…¥ MyTT (å‡è®¾ç”¨æˆ·å·²æ”¾ç½®æ–‡ä»¶) ===
try:
    # ä¼˜å…ˆå°è¯•ä½œä¸ºæ¨¡å—å¯¼å…¥
    import MyTT 
except ImportError:
    try:
        # å°è¯• import indicators (å¦‚æœç”¨æˆ·é‡å‘½åäº†)
        import indicators as MyTT
    except ImportError:
        MyTT = None
        print("âš ï¸ Warning: MyTT.py not found. Technical indicators will be skipped.")

# === é‚®ä»¶ç›¸å…³åº“ ===
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders

ENV_KEYS = {
    "FMP": os.environ.get("FMP_API_Key"),
}

# ========================================================
# æŠ€æœ¯æŒ‡æ ‡è®¡ç®—è¾…åŠ©å‡½æ•°
# ========================================================
def calculate_tech_indicators(df):
    """
    ä½¿ç”¨ MyTT è®¡ç®— MACD, KDJ, RSI
    df: å¿…é¡»åŒ…å« 'close', 'high', 'low', 'open' åˆ— (å°å†™)
    """
    if MyTT is None or df.empty:
        return {}
    
    try:
        # MyTT éœ€è¦ numpy array æˆ– pandas series
        CLOSE = df['close'].values
        HIGH = df['high'].values
        LOW = df['low'].values
        OPEN = df['open'].values
        
        # 1. MACD (12, 26, 9)
        # MyTT.MACD è¿”å›: DIF, DEA, MACD
        dif, dea, macd_bar = MyTT.MACD(CLOSE)
        
        # 2. KDJ (9, 3, 3)
        # MyTT.KDJ è¿”å›: K, D, J
        k, d, j = MyTT.KDJ(CLOSE, HIGH, LOW)
        
        # 3. RSI (6)
        # MyTT.RSI è¿”å›: RSI
        rsi6 = MyTT.RSI(CLOSE, 6)
        
        # å–æœ€æ–°å€¼ (æœ€åä¸€ä¸ª)
        latest_idx = -1
        
        # ç®€å•çš„ä¿¡å·åˆ¤æ–­
        signals = []
        
        # MACD é‡‘å‰: æ˜¨å¤© DIF < DEA, ä»Šå¤© DIF > DEA
        if len(dif) > 1:
            if dif[-2] < dea[-2] and dif[-1] > dea[-1]:
                signals.append("MACDé‡‘å‰")
            elif dif[-2] > dea[-2] and dif[-1] < dea[-1]:
                signals.append("MACDæ­»å‰")
                
        # KDJ é‡‘å‰
        if len(k) > 1:
            if k[-2] < d[-2] and k[-1] > d[-1]:
                signals.append("KDJé‡‘å‰")
        
        # RSI è¶…ä¹°è¶…å–
        if rsi6[-1] > 80:
            signals.append("RSIè¶…ä¹°")
        elif rsi6[-1] < 20:
            signals.append("RSIè¶…å–")

        # [ä¿®æ”¹] å¦‚æœæ²¡æœ‰ç‰¹æ®Šå½¢æ€ï¼Œæ˜¾å¼å†™å…¥è¯´æ˜ï¼Œä¿ç•™åœ¨JSONä¸­
        if not signals:
            signals.append("æ— ç‰¹æ®ŠæŠ€æœ¯å½¢æ€")

        return {
            "MACD": round(float(macd_bar[-1]), 4),
            "DIF": round(float(dif[-1]), 4),
            "DEA": round(float(dea[-1]), 4),
            "K": round(float(k[-1]), 2),
            "D": round(float(d[-1]), 2),
            "J": round(float(j[-1]), 2),
            "RSI6": round(float(rsi6[-1]), 2),
            "Signals": signals
        }

    except Exception as e:
        print(f"Error calculating indicators: {e}")
        return {}

class MarketFetcher:
    def __init__(self, fetch_start_date, end_date):
        self.session = requests.Session()
        self.fetch_start_date = fetch_start_date
        self.end_date = end_date
    
    def normalize_df(self, df, name):
        """ç»Ÿä¸€æ¸…æ´—Kçº¿æ•°æ®æ ¼å¼å¹¶è‡ªåŠ¨è¡¥å…¨æŒ‡æ ‡"""
        if df.empty: return df
        
        # 1. ç»Ÿä¸€åˆ—å (Lower case)
        df.columns = [c.lower() for c in df.columns]
        
        # 2. å¤„ç†æ—¥æœŸåˆ—å
        if 'date' not in df.columns and 'æ—¥æœŸ' in df.columns:
            df.rename(columns={'æ—¥æœŸ': 'date'}, inplace=True)
        
        # 3. å¤„ç† AkShare ä¸­æ–‡åˆ—åæ˜ å°„
        rename_map = {
            'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close', 'æœ€é«˜': 'high', 'æœ€ä½': 'low', 
            'æˆäº¤é‡': 'volume', 'äº¤æ˜“é‡': 'volume', 'æŒä»“é‡': 'open_interest',
            'æˆäº¤é¢': 'amount', 'é‡æ¯”': 'volume_ratio',
            'å¼€ç›˜ä»·': 'open', 'æ”¶ç›˜ä»·': 'close', 'æœ€é«˜ä»·': 'high', 'æœ€ä½ä»·': 'low', 
            'date': 'date' 
        }
        df.rename(columns=rename_map, inplace=True)
        
        # 4. ç¡®ä¿æ—¥æœŸæ ¼å¼å¹¶æ’åº (è®¡ç®—æŒ‡æ ‡å¿…é¡»æŒ‰æ—¶é—´é¡ºåº)
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values(by='date', ascending=True)
        
        # 5. ç¡®ä¿åŒ…å«åŸºç¡€åˆ— (ä¸å­˜åœ¨åˆ™å…ˆç½®ä¸ºç©º)
        for col in ['open', 'close', 'high', 'low', 'volume']:
            if col not in df.columns:
                df[col] = 0.0
        
        if 'name' not in df.columns:
            df['name'] = name

        # 6. æ•°å€¼è½¬æ¢ (å¤„ç†å¯èƒ½çš„å­—ç¬¦ä¸², é€—å·ç­‰)
        cols_to_numeric = ['open', 'close', 'high', 'low', 'volume', 'amount', 'volume_ratio']
        for col in cols_to_numeric:
            if col in df.columns:
                if df[col].dtype == object:
                     df[col] = df[col].astype(str).str.replace(',', '').apply(pd.to_numeric, errors='coerce')
                else:
                     df[col] = pd.to_numeric(df[col], errors='coerce')

        # 7. è¡¥å…¨/è®¡ç®— æˆäº¤é¢ (Amount)
        if 'amount' not in df.columns or df['amount'].isna().all():
            df['amount'] = df['close'] * df['volume']
        else:
            df['amount'] = df['amount'].fillna(df['close'] * df['volume'])
            
        # 8. è¡¥å…¨/è®¡ç®— é‡æ¯” (Volume Ratio)
        need_calc_vr = False
        if 'volume_ratio' not in df.columns:
            need_calc_vr = True
        elif df['volume_ratio'].isna().all():
            need_calc_vr = True
        
        if need_calc_vr:
            ma5_vol = df['volume'].rolling(window=5, min_periods=1).mean().shift(1)
            df['volume_ratio'] = df['volume'] / ma5_vol
            df['volume_ratio'] = df['volume_ratio'].replace([float('inf'), -float('inf')], 0.0).fillna(0.0)

        # 9. æœ€ç»ˆåˆ—ç­›é€‰ä¸å¡«å……
        final_cols = ['date', 'name', 'open', 'close', 'high', 'low', 'volume', 'amount', 'volume_ratio']
        
        for col in final_cols:
            if col not in df.columns:
                df[col] = 0.0
        
        df.fillna(0, inplace=True)

        # æ ¼å¼åŒ–ç‰¹å®šåˆ—ï¼šå¦‚æœå€¼ä¸º 0 åˆ™è¾“å‡º "-"
        cols_to_check = ['volume', 'amount', 'volume_ratio']
        for col in cols_to_check:
            def replace_zero(x):
                try:
                    if float(x) == 0:
                        return "-"
                except:
                    pass
                return x
            df[col] = df[col].apply(replace_zero)

        return df[final_cols]

    def fetch_akshare(self, symbol, asset_type):
        if not symbol: return pd.DataFrame()
        max_retries = 5
        
        for i in range(max_retries):
            retry_msg = f" [é‡è¯•{i}]" if i > 0 else ""
            print(f"   âš¡ [AkShare] è¯·æ±‚: {symbol} ({asset_type}){retry_msg} ...", end="", flush=True)

            try:
                df = pd.DataFrame()
                start_date_clean = self.fetch_start_date.replace("-", "")
                end_date_clean = self.end_date.replace("-", "")

                if asset_type == "index_us":
                    df = ak.index_us_stock_sina(symbol=symbol)
                elif asset_type == "index_hk":
                    df = ak.stock_hk_index_daily_sina(symbol=symbol)
                elif asset_type == "gold_cn":
                    df = ak.spot_hist_sge(symbol=symbol)
                elif asset_type == "future_foreign":
                    df = ak.futures_foreign_hist(symbol=symbol)
                elif asset_type == "stock_hk":
                    df = ak.stock_hk_daily(symbol=symbol, adjust="qfq")
                elif asset_type == "stock_vn":
                    try:
                        df = ak.stock_vn_hist(symbol=symbol)
                    except:
                        df = pd.DataFrame()
                elif asset_type == "stock_us":
                    df = ak.stock_us_daily(symbol=symbol, adjust="qfq")
                elif asset_type == "future_zh_sina":
                    df = ak.futures_main_sina(symbol=symbol)
                elif asset_type == "etf_zh":
                    df = ak.fund_etf_hist_em(symbol=symbol, period="daily", start_date=start_date_clean, end_date=end_date_clean, adjust="qfq")
                elif asset_type == "stock_zh_a":
                    df = ak.stock_zh_a_hist(symbol=symbol, period="daily", start_date=start_date_clean, end_date=end_date_clean, adjust="qfq")
                
                if not df.empty:
                    print(" âœ…")
                    return df
                else:
                    print(" âŒ (ç©ºæ•°æ®)")
                    return pd.DataFrame()

            except Exception as e:
                print(f" âŒ (Err: {str(e)[:15]})")
                if i < max_retries - 1:
                    time.sleep(2)
                continue
        
        print(" âŒ (AkShareå¤šæ¬¡é‡è¯•å¤±è´¥, æ”¾å¼ƒ)")
        return pd.DataFrame()

    def fetch_yfinance(self, symbol):
        if not symbol: return pd.DataFrame()
        max_retries = 5
        
        for i in range(max_retries):
            retry_msg = f" [é‡è¯•{i}]" if i > 0 else ""
            print(f"   âš¡ [YFinance] è¯·æ±‚: {symbol}{retry_msg} ...", end="", flush=True)
            
            try:
                df = yf.download(symbol, start=self.fetch_start_date, end=self.end_date, progress=False, auto_adjust=False)
                if not df.empty:
                    df = df.reset_index()
                    if isinstance(df.columns, pd.MultiIndex):
                        df.columns = df.columns.droplevel(1)
                    print(" âœ…")
                    return df
                else:
                    print(" âŒ (ç©ºæ•°æ®)")
                    return pd.DataFrame()
            except Exception as e:
                print(f" âŒ (Err: {str(e)[:15]})")
                if i < max_retries - 1:
                    time.sleep(2)
                continue

        print(" âŒ (YFinanceå¤šæ¬¡é‡è¯•å¤±è´¥, æ”¾å¼ƒ)")
        return pd.DataFrame()

    def fetch_fmp(self, name):
        key = ENV_KEYS.get("FMP")
        if not key: return pd.DataFrame()
        
        symbol_map = {
            "çº³æ–¯è¾¾å…‹": "^IXIC", "æ ‡æ™®500": "^GSPC", 
            "é»„é‡‘(COMEX)": "GCUSD", "VNM(ETF)": "VNM",
            "è¶Šå—èƒ¡å¿—æ˜æŒ‡æ•°": "^VNINDEX"
        }
        symbol = symbol_map.get(name)
        if not symbol: return pd.DataFrame()

        print(f"   âš¡ [FMP] è¯·æ±‚: {symbol} ...", end="", flush=True)
        try:
            url = f"https://financialmodelingprep.com/api/v3/historical-price-full/{symbol}?from={self.fetch_start_date}&to={self.end_date}&apikey={key}"
            res = requests.get(url, timeout=10) 
            data = res.json()
            if "historical" in data:
                df = pd.DataFrame(data["historical"])
                print(" âœ…")
                return df
        except:
            print(" âŒ")
        return pd.DataFrame()

    def get_kline_data(self, name, config):
        print(f"æ­£åœ¨è·å– Kçº¿ [{name}] ...")
        time.sleep(random.uniform(1.0, 3.0))
        
        df = pd.DataFrame()
        if config.get("ak"):
            df = self.fetch_akshare(config.get("ak"), config.get("type"))
            df = self.normalize_df(df, name)
        
        if df.empty:
            df = self.fetch_yfinance(config.get("yf"))
            df = self.normalize_df(df, name)

        if df.empty:
            df = self.fetch_fmp(name)
            df = self.normalize_df(df, name)
            
        return df

def fetch_group_data(fetcher, targets, group_name, report_start_date, end_date):
    """
    é€šç”¨å‡½æ•°ï¼šè¿”å› (Kçº¿æ•°æ®åˆ—è¡¨, å‡çº¿æ•°æ®åˆ—è¡¨, çŠ¶æ€æ—¥å¿—åˆ—è¡¨)
    """
    print(f"\nğŸš€ å¼€å§‹å¤„ç†ä»»åŠ¡ç»„: {group_name} (å¹¶å‘æ¨¡å¼)")
    
    kline_list = []
    ma_list = []
    status_logs = []
    
    def fetch_task(name, config):
        try:
            # 1. è·å–é•¿å‘¨æœŸæ•°æ® (ç”¨äºè®¡ç®—å‡çº¿å’ŒæŒ‡æ ‡)
            df = fetcher.get_kline_data(name, config)
            if df.empty:
                return None, None, {'name': name, 'status': False, 'error': "Data source returned empty after retries"}
            
            # ç¡®ä¿æ—¥æœŸå‡åº
            df = df.sort_values(by='date', ascending=True)

            # 2. è®¡ç®—å‡çº¿
            ma_info_list = utils.calculate_ma(df) 
            ma_info = ma_info_list[0] if ma_info_list else None
            
            # 3. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ (MyTT) - å–æœ€æ–°çš„ä¸€ä¸ªç‚¹
            tech_indicators = calculate_tech_indicators(df)
            
            # å¦‚æœæœ‰å‡çº¿ä¿¡æ¯ï¼ŒæŠŠæŠ€æœ¯æŒ‡æ ‡åˆå¹¶è¿›å»
            if ma_info:
                ma_info.update(tech_indicators)

            # 4. åˆ‡ç‰‡ä¸ºç”¨æˆ·é…ç½®çš„çŸ­å‘¨æœŸ (ç”¨äºå±•ç¤º Kçº¿å›¾)
            df_slice = df[(df['date'] >= pd.to_datetime(report_start_date)) & (df['date'] <= pd.to_datetime(end_date))].copy()
            
            # æ ¼å¼åŒ–æ—¥æœŸ
            if not df_slice.empty:
                df_slice['date'] = df_slice['date'].dt.strftime('%Y-%m-%d')
                kline_records = df_slice.to_dict(orient='records')
            else:
                kline_records = []
            
            # å°†æŠ€æœ¯æŒ‡æ ‡ä¹Ÿé™„åŠ åˆ° Kçº¿è®°å½•çš„æœ€åä¸€æ¡ï¼ˆå¯é€‰ï¼Œæˆ–è€…å‰ç«¯åªå±•ç¤ºæœ€æ–°ï¼‰
            # è¿™é‡Œæˆ‘ä»¬ä¸»è¦ä¾èµ– ma_info (å®ƒå…¶å®æ˜¯ latest_info) æ¥ä¼ é€’æŒ‡æ ‡
            
            return kline_records, ma_info, {'name': name, 'status': True, 'error': None}

        except Exception as e:
            print(f"âŒ ä»»åŠ¡ {name} å¼‚å¸¸: {e}")
            return None, None, {'name': name, 'status': False, 'error': str(e)}

    with ThreadPoolExecutor(max_workers=4) as executor:
        future_to_name = {executor.submit(fetch_task, name, config): name for name, config in targets.items()}
        
        for future in as_completed(future_to_name):
            name = future_to_name[future]
            try:
                result = future.result(timeout=20) # ç¨å¾®å¢åŠ è¶…æ—¶æ—¶é—´
                klines, ma, status = result
                
                status_logs.append(status)
                
                if klines:
                    kline_list.extend(klines)
                else:
                    print(f"âš ï¸ è­¦å‘Š: æ— æ³•è·å– {name} çš„Kçº¿æ•°æ® (èŒƒå›´ä¸ºç©º?)")
                
                if ma:
                    ma_list.append(ma)
                    
            except TimeoutError:
                print(f" ğŸ’€ ä¸¥é‡è¶…æ—¶: è·å– {name} è¶…è¿‡20ç§’æ— å“åº”ï¼Œå¼ºåˆ¶è·³è¿‡ï¼")
                status_logs.append({'name': name, 'status': False, 'error': "Thread timed out"})
            except Exception as e:
                print(f"âŒ å¤„ç† {name} ç»“æœæ—¶å‡ºé”™: {e}")
                status_logs.append({'name': name, 'status': False, 'error': f"Processing error: {str(e)}"})

    if kline_list:
        temp_df = pd.DataFrame(kline_list)
        temp_df.sort_values(by=['date', 'name'], ascending=[False, True], inplace=True)
        final_kline_data = temp_df.to_dict(orient='records')
    else:
        final_kline_data = []

    return final_kline_data, ma_list, status_logs

def send_email(subject, body, attachment_files, sender_email, sender_password, receiver_email, smtp_server, smtp_port, enable_email):
    """
    å‘é€å¸¦æœ‰å¤šä¸ªé™„ä»¶çš„é‚®ä»¶ (QQé‚®ç®±ä½¿ç”¨ SMTP_SSL:465)
    """
    if not enable_email:
        print("\nğŸ”• é‚®ä»¶åŠŸèƒ½å·²å…³é—­ï¼Œè·³è¿‡å‘é€ã€‚")
        return
    
    if not sender_email or not sender_password:
        print("\nâŒ é”™è¯¯ï¼šæœªæ£€æµ‹åˆ° SENDER_EMAIL æˆ– SENDER_PASSWORD ç¯å¢ƒå˜é‡ï¼Œæ— æ³•å‘é€é‚®ä»¶ï¼")
        return

    print("\nğŸ“§ æ­£åœ¨å‡†å¤‡å‘é€é‚®ä»¶...")
    
    msg = MIMEMultipart()
    msg['From'] = sender_email
    msg['To'] = receiver_email
    msg['Subject'] = subject

    msg.attach(MIMEText(body, 'plain'))

    attachment_count = 0
    for file_path in attachment_files:
        if os.path.exists(file_path):
            try:
                with open(file_path, "rb") as attachment:
                    part = MIMEBase("application", "octet-stream")
                    part.set_payload(attachment.read())
                
                encoders.encode_base64(part)
                
                filename = os.path.basename(file_path)
                part.add_header('Content-Disposition', 'attachment', filename=filename)
                
                msg.attach(part)
                print(f"   ğŸ“ å·²æ·»åŠ é™„ä»¶: {filename}")
                attachment_count += 1
            except Exception as e:
                print(f"   âŒ æ·»åŠ é™„ä»¶ {file_path} å¤±è´¥: {e}")
        else:
            print(f"   âš ï¸ é™„ä»¶æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    if attachment_count == 0:
        print("âš ï¸ è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆé™„ä»¶è¢«æ·»åŠ ï¼Œä»å°è¯•å‘é€é‚®ä»¶...")

    try:
        print(f"ğŸš€ è¿æ¥ SMTP æœåŠ¡å™¨ {smtp_server}:{smtp_port} (SSL) å¹¶å‘é€...")
        server = smtplib.SMTP_SSL(smtp_server, smtp_port)
        server.login(sender_email, sender_password)
        server.sendmail(sender_email, receiver_email, msg.as_string())
        server.quit()
        print("âœ… é‚®ä»¶å‘é€æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")