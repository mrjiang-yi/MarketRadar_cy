#yuan si de dai ma
import pandas as pd
import numpy as np
import requests
import json
import os

def calculate_ma(df, windows=[5, 10, 20, 60, 120, 250]):
    """
    è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
    """
    if df is None or df.empty or 'close' not in df.columns:
        return []

    df = df.sort_values('date').copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    if 'name' in df.columns:
        groups = df.groupby('name')
    else:
        groups = [('Unknown', df)]

    final_results = []

    for name, group_df in groups:
        if len(group_df) < 1:
            continue
            
        latest_record = group_df.iloc[-1].to_dict()
        
        date_val = latest_record.get('date')
        if isinstance(date_val, pd.Timestamp):
            date_str = date_val.strftime('%Y-%m-%d')
        else:
            date_str = str(date_val)

        # è®¡ç®—æ¶¨è·Œå¹… (ç›¸å¯¹äºå‰ä¸€å¤©)
        change_pct = 0.0
        if len(group_df) >= 2:
            prev_close = group_df['close'].iloc[-2]
            curr_close = group_df['close'].iloc[-1]
            if prev_close > 0:
                change_pct = round((curr_close - prev_close) / prev_close * 100, 2)

        ma_data = {
            "åç§°": name,
            "æ—¥æœŸ": date_str,
            "æ”¶ç›˜ä»·": round(latest_record.get('close'), 2),
            "æ¶¨è·Œå¹…": f"{change_pct}%"
        }

        for w in windows:
            col_name = f"{w}æ—¥å‡çº¿"
            ma_series = group_df['close'].rolling(window=w).mean()
            latest_ma = ma_series.iloc[-1]
            if pd.notna(latest_ma):
                ma_data[col_name] = round(latest_ma, 2)
            else:
                ma_data[col_name] = None

        final_results.append(ma_data)
        
    return final_results

# def send_to_feishu(webhook_url, report_data):
#     """
#     å‘é€æ¶ˆæ¯åˆ°é£ä¹¦
#     """
#     if not webhook_url:
#         print("âš ï¸ æœªé…ç½® FEISHU_WEBHOOK_URLï¼Œè·³è¿‡æ¨é€")
#         return False

#     try:
#         # æå–æ—¥æœŸ
#         report_date = report_data.get('meta', {}).get('generated_at', 'Unknown')[:10]
        
#         # æå–è‡ªå®šä¹‰æ ‡çš„ (ç”¨äºåœ¨å¡ç‰‡ä¸­å¿«é€Ÿé¢„è§ˆ)
#         custom_funds = report_data.get("market_klines", {}).get("è‡ªå®šä¹‰ç²¾é€‰", [])
        
#         # æ•´ç†è‡ªå®šä¹‰æ ‡çš„é¢„è§ˆæ–‡æœ¬ (å–å‰ 20 ä¸ªï¼Œé˜²æ­¢æ¶ˆæ¯è¿‡é•¿)
#         preview_lines = []
#         for f in custom_funds[:20]: 
#             # è¿™é‡Œçš„ f æ˜¯ Kçº¿æ•°æ®çš„ latest recordï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°å®ƒçš„åå­—å’Œæœ€æ–°æ”¶ç›˜ä»·
#             # market_klines ç»“æ„æ˜¯ {"è‡ªå®šä¹‰ç²¾é€‰": [{date, name, close...}, {date, name, close...}]}
#             # ä½†ä¼ å…¥çš„ json å·²ç»æ˜¯ list of recordsï¼Œå¯èƒ½åŒ…å«å†å²æ•°æ®
#             pass

#         # ä¸Šé¢çš„ custom_funds æ˜¯æ‰€æœ‰å†å²æ•°æ®çš„æ‰å¹³åˆ—è¡¨ï¼Œæˆ‘ä»¬éœ€è¦æå–æ¯ä¸ªæ ‡çš„çš„æœ€æ–°ä¸€æ¡
#         # æ›´æ–¹ä¾¿çš„æ˜¯ä» ma_data (æŠ€æœ¯åˆ†æ) ä¸­æå–ï¼Œå› ä¸º calculate_ma å·²ç»åªè¿”å›æœ€æ–°ä¸€æ¡äº†
#         ma_list = report_data.get("æŠ€æœ¯åˆ†æ", {}).get("æŒ‡æ•°+ä¸ªè‚¡æ—¥å‡çº¿", [])
        
#         # ç­›é€‰å‡ºå±äº "è‡ªå®šä¹‰ç²¾é€‰" çš„æ ‡çš„åç§°
#         # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ç›´æ¥éå† ma_listï¼ŒæŠŠå‡ ä¸ªå…³é”®çš„åˆ—å‡ºæ¥
        
#         fund_preview = ""
#         # å®šä¹‰éœ€è¦é«˜äº®å…³æ³¨çš„å…³é”®è¯
#         keywords = ["ETF", "LOF", "ä¿é™©", "ç¨€åœŸ", "è¯ºå®‰", "äººå·¥æ™ºèƒ½", "æœ‰è‰²"]
        
#         count = 0
#         for item in ma_list:
#             name = item.get("åç§°", "")
#             if any(k in name for k in keywords):
#                 price = item.get("æ”¶ç›˜ä»·", 0)
#                 pct = item.get("æ¶¨è·Œå¹…", "0%")
                
#                 # ç®€å•çš„ emoji æŒ‡ç¤º
#                 icon = "ğŸ”´" if "-" not in str(pct) and pct != "0%" and pct != "0.0%" else "ğŸŸ¢"
                
#                 fund_preview += f"{icon} {name}: {price} ({pct})\n"
#                 count += 1
#                 if count >= 15: break # é™åˆ¶æ˜¾ç¤ºæ•°é‡

#         if not fund_preview:
#             fund_preview = "æš‚æ— ç›¸å…³æ ‡çš„æ•°æ®"

#         # æ„é€ é£ä¹¦å¡ç‰‡æ¶ˆæ¯
#         payload = {
#             "msg_type": "post",
#             "content": {
#                 "post": {
#                     "zh_cn": {
#                         "title": f"ğŸ“Š MarketRadar æ—¥æŠ¥ ({report_date})",
#                         "content": [
#                             [{"tag": "text", "text": "âœ… æ•°æ®æŠ“å–ä»»åŠ¡å·²å®Œæˆ (Selenium/AkShare/YFinance)"}],
#                             [{"tag": "text", "text": "\nã€é‡ç‚¹å…³æ³¨æ ‡çš„ã€‘:"}],
#                             [{"tag": "text", "text": fund_preview}],
#                             [{"tag": "text", "text": "\nè¯¦ç»† JSON æŠ¥å‘Šå·²ç”Ÿæˆå¹¶å‘é€è‡³é‚®ç®±ã€‚"}],
#                             [{"tag": "a", "text": "æŸ¥çœ‹ GitHub Actions", "href": "https://github.com/"}]
#                         ]
#                     }
#                 }
#             }
#         }
        
#         headers = {"Content-Type": "application/json"}
#         res = requests.post(webhook_url, data=json.dumps(payload), headers=headers, timeout=10)
        
#         if res.status_code == 200:
#             print("ğŸš€ é£ä¹¦æ¨é€æˆåŠŸï¼")
#             return True
#         else:
#             print(f"âŒ é£ä¹¦æ¨é€å¤±è´¥: {res.text}")
#             return False

#     except Exception as e:
#         print(f"âŒ é£ä¹¦æ¨é€å¼‚å¸¸: {e}")
#         return False

def send_to_feishu(webhook_url, report_data):
    """
    å‘é€å¢å¼ºå‹å¯Œæ–‡æœ¬æ¶ˆæ¯åˆ°é£ä¹¦æœºå™¨äºº
    1. å±•ç¤ºå®¹é‡æå‡è‡³ 12 ä¸ª
    2. åŠ å…¥æ¶¨è·Œè¶‹åŠ¿å›¾æ ‡ä¸å‡çº¿çŠ¶æ€
    """
    if not webhook_url:
        print("âš ï¸ æç¤º: æœªé…ç½® FEISHU_WEBHOOK_URLï¼Œè·³è¿‡æ¨é€")
        return False

    try:
        # æŒ‰ç…§ä½ åŸå§‹ä»£ç çš„è·¯å¾„æå–æ•°æ®
        # å¦‚æœä½ çš„ main.py ç»“æ„æ²¡å˜ï¼Œè¿™é‡Œä¾ç„¶ä½¿ç”¨ "market_kline" å’Œ "è‡ªå®šä¹‰æ ‡çš„"
        custom_funds = report_data.get("market_kline", {}).get("è‡ªå®šä¹‰æ ‡çš„", [])
        
        # 1. æ„é€ å¢å¼ºå‹é¢„è§ˆæ–‡å­—
        content_lines = []
        # --- å…³é”®ä¿®æ”¹ï¼šå®¹é‡ä» [:10] å¢åŠ åˆ° [:12] ---
        for f in custom_funds[:12]:
            name = f.get('name', 'æœªçŸ¥')
            price = f.get('close', 0.0)
            
            # å°è¯•è·å–æ¶¨è·Œå¹… (å¦‚æœä½ çš„ main.py å·²è®¡ç®—è¯¥å­—æ®µ)
            chg = f.get('change_pct', 0.0)
            trend_icon = "ğŸ”º" if chg >= 0 else "ğŸ”»"
            
            # å°è¯•è·å–å‡çº¿çŠ¶æ€ (å¦‚æœ price > ma20)
            ma20 = f.get('ma20')
            ma_status = ""
            if ma20:
                ma_status = " [20æ—¥çº¿ä¸Š]" if price > ma20 else " [20æ—¥çº¿ä¸‹]"

            # ç»„è£…å•è¡Œå†…å®¹
            line = f"â€¢ {name}: {price} ({trend_icon}{abs(chg):.2f}%){ma_status}"
            content_lines.append([{"tag": "text", "text": line}])

        # 2. æ„é€ é£ä¹¦æ¶ˆæ¯ä½“ (å¯Œæ–‡æœ¬æ ¼å¼)
        report_date = report_data.get('report_date', 'Today')
        payload = {
            "msg_type": "post",
            "content": {
                "post": {
                    "zh_cn": {
                        "title": f"ğŸ“ˆ MarketRadar è¡Œæƒ…å¿«æŠ¥ ({report_date})",
                        "content": [
                            [{"tag": "text", "text": "âœ… æ ¸å¿ƒæ ‡çš„æ•°æ®å·²æ›´æ–°ï¼ˆå‰12é¡¹ï¼‰ï¼š"}]
                        ] + content_lines + [
                            [{"tag": "text", "text": "---------------------------"}] ,
                            [{"tag": "text", "text": "ğŸ“‚ æ›´å¤šæŠ€æœ¯æŒ‡æ ‡ä¸å…¨é‡ JSON è¯·æŸ¥çœ‹é‚®ä»¶é™„ä»¶ã€‚"}]
                        ]
                    }
                }
            }
        }
        
        headers = {"Content-Type": "application/json"}
        response = requests.post(webhook_url, data=json.dumps(payload), headers=headers, timeout=10)
        
        if response.status_code == 200:
            print("ğŸš€ é£ä¹¦ 12 é¡¹æŒ‡æ ‡æ¶ˆæ¯å‘é€æˆåŠŸï¼")
            return True
        else:
            print(f"âŒ é£ä¹¦æ¨é€å¤±è´¥: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ é£ä¹¦æ¨é€å¼‚å¸¸: {e}")
        return False
























