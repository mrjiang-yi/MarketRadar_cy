#yuan si de dai ma
import pandas as pd
import numpy as np
import requests
import json
import os

def calculate_ma(df, windows=[5, 10, 20, 60, 120, 250]):
    """
    è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
    """
    if df is None or df.empty or 'close' not in df.columns:
        return []

    df = df.sort_values('date').copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    
    if 'name' in df.columns:
        groups = df.groupby('name')
    else:
        groups = [('Unknown', df)]

    final_results = []

    for name, group_df in groups:
        if len(group_df) < 1:
            continue
            
        latest_record = group_df.iloc[-1].to_dict()
        
        date_val = latest_record.get('date')
        if isinstance(date_val, pd.Timestamp):
            date_str = date_val.strftime('%Y-%m-%d')
        else:
            date_str = str(date_val)

        # è®¡ç®—æ¶¨è·Œå¹… (ç›¸å¯¹äºå‰ä¸€å¤©)
        change_pct = 0.0
        if len(group_df) >= 2:
            prev_close = group_df['close'].iloc[-2]
            curr_close = group_df['close'].iloc[-1]
            if prev_close > 0:
                change_pct = round((curr_close - prev_close) / prev_close * 100, 2)

        ma_data = {
            "åç§°": name,
            "æ—¥æœŸ": date_str,
            "æ”¶ç›˜ä»·": round(latest_record.get('close'), 2),
            "æ¶¨è·Œå¹…": f"{change_pct}%"
        }

        for w in windows:
            col_name = f"{w}æ—¥å‡çº¿"
            ma_series = group_df['close'].rolling(window=w).mean()
            latest_ma = ma_series.iloc[-1]
            if pd.notna(latest_ma):
                ma_data[col_name] = round(latest_ma, 2)
            else:
                ma_data[col_name] = None

        final_results.append(ma_data)
        
    return final_results

# def send_to_feishu(webhook_url, report_data):
#     """
#     å‘é€æ¶ˆæ¯åˆ°é£ä¹¦
#     """
#     if not webhook_url:
#         print("âš ï¸ æœªé…ç½® FEISHU_WEBHOOK_URLï¼Œè·³è¿‡æ¨é€")
#         return False

#     try:
#         # æå–æ—¥æœŸ
#         report_date = report_data.get('meta', {}).get('generated_at', 'Unknown')[:10]
        
#         # æå–è‡ªå®šä¹‰æ ‡çš„ (ç”¨äºåœ¨å¡ç‰‡ä¸­å¿«é€Ÿé¢„è§ˆ)
#         custom_funds = report_data.get("market_klines", {}).get("è‡ªå®šä¹‰ç²¾é€‰", [])
        
#         # æ•´ç†è‡ªå®šä¹‰æ ‡çš„é¢„è§ˆæ–‡æœ¬ (å–å‰ 20 ä¸ªï¼Œé˜²æ­¢æ¶ˆæ¯è¿‡é•¿)
#         preview_lines = []
#         for f in custom_funds[:20]: 
#             # è¿™é‡Œçš„ f æ˜¯ Kçº¿æ•°æ®çš„ latest recordï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°å®ƒçš„åå­—å’Œæœ€æ–°æ”¶ç›˜ä»·
#             # market_klines ç»“æ„æ˜¯ {"è‡ªå®šä¹‰ç²¾é€‰": [{date, name, close...}, {date, name, close...}]}
#             # ä½†ä¼ å…¥çš„ json å·²ç»æ˜¯ list of recordsï¼Œå¯èƒ½åŒ…å«å†å²æ•°æ®
#             pass

#         # ä¸Šé¢çš„ custom_funds æ˜¯æ‰€æœ‰å†å²æ•°æ®çš„æ‰å¹³åˆ—è¡¨ï¼Œæˆ‘ä»¬éœ€è¦æå–æ¯ä¸ªæ ‡çš„çš„æœ€æ–°ä¸€æ¡
#         # æ›´æ–¹ä¾¿çš„æ˜¯ä» ma_data (æŠ€æœ¯åˆ†æ) ä¸­æå–ï¼Œå› ä¸º calculate_ma å·²ç»åªè¿”å›æœ€æ–°ä¸€æ¡äº†
#         ma_list = report_data.get("æŠ€æœ¯åˆ†æ", {}).get("æŒ‡æ•°+ä¸ªè‚¡æ—¥å‡çº¿", [])
        
#         # ç­›é€‰å‡ºå±äº "è‡ªå®šä¹‰ç²¾é€‰" çš„æ ‡çš„åç§°
#         # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ç›´æ¥éå† ma_listï¼ŒæŠŠå‡ ä¸ªå…³é”®çš„åˆ—å‡ºæ¥
        
#         fund_preview = ""
#         # å®šä¹‰éœ€è¦é«˜äº®å…³æ³¨çš„å…³é”®è¯
#         keywords = ["ETF", "LOF", "ä¿é™©", "ç¨€åœŸ", "è¯ºå®‰", "äººå·¥æ™ºèƒ½", "æœ‰è‰²"]
        
#         count = 0
#         for item in ma_list:
#             name = item.get("åç§°", "")
#             if any(k in name for k in keywords):
#                 price = item.get("æ”¶ç›˜ä»·", 0)
#                 pct = item.get("æ¶¨è·Œå¹…", "0%")
                
#                 # ç®€å•çš„ emoji æŒ‡ç¤º
#                 icon = "ğŸ”´" if "-" not in str(pct) and pct != "0%" and pct != "0.0%" else "ğŸŸ¢"
                
#                 fund_preview += f"{icon} {name}: {price} ({pct})\n"
#                 count += 1
#                 if count >= 15: break # é™åˆ¶æ˜¾ç¤ºæ•°é‡

#         if not fund_preview:
#             fund_preview = "æš‚æ— ç›¸å…³æ ‡çš„æ•°æ®"

#         # æ„é€ é£ä¹¦å¡ç‰‡æ¶ˆæ¯
#         payload = {
#             "msg_type": "post",
#             "content": {
#                 "post": {
#                     "zh_cn": {
#                         "title": f"ğŸ“Š MarketRadar æ—¥æŠ¥ ({report_date})",
#                         "content": [
#                             [{"tag": "text", "text": "âœ… æ•°æ®æŠ“å–ä»»åŠ¡å·²å®Œæˆ (Selenium/AkShare/YFinance)"}],
#                             [{"tag": "text", "text": "\nã€é‡ç‚¹å…³æ³¨æ ‡çš„ã€‘:"}],
#                             [{"tag": "text", "text": fund_preview}],
#                             [{"tag": "text", "text": "\nè¯¦ç»† JSON æŠ¥å‘Šå·²ç”Ÿæˆå¹¶å‘é€è‡³é‚®ç®±ã€‚"}],
#                             [{"tag": "a", "text": "æŸ¥çœ‹ GitHub Actions", "href": "https://github.com/"}]
#                         ]
#                     }
#                 }
#             }
#         }
        
#         headers = {"Content-Type": "application/json"}
#         res = requests.post(webhook_url, data=json.dumps(payload), headers=headers, timeout=10)
        
#         if res.status_code == 200:
#             print("ğŸš€ é£ä¹¦æ¨é€æˆåŠŸï¼")
#             return True
#         else:
#             print(f"âŒ é£ä¹¦æ¨é€å¤±è´¥: {res.text}")
#             return False

#     except Exception as e:
#         print(f"âŒ é£ä¹¦æ¨é€å¼‚å¸¸: {e}")
#         return False
def send_to_feishu(webhook_url, report_data):
    if not webhook_url:
        print("âš ï¸ æç¤º: æœªé…ç½® FEISHU_WEBHOOK_URLï¼Œè·³è¿‡æ¨é€")
        return False

    try:
        # 1. è·å–æ‰€æœ‰ K çº¿åˆ†ç±»æ•°æ®
        all_klines = report_data.get("market_klines", {})
        if not all_klines:
            # å…¼å®¹æ—§ç‰ˆæˆ–ä¸åŒå±‚çº§ç»“æ„
            all_klines = report_data.get("market_kline", {})

        content_lines = []
        
        # 2. éå†æ‰€æœ‰åˆ†ç±» (åŒ…æ‹¬æœ‰è‰²ã€åˆ¸å•†ã€ç¾è‚¡ç­‰)
        for cat_name, items in all_klines.items():
            if not items or not isinstance(items, list):
                continue
            
            # åˆ†ç±»æ ‡é¢˜
            content_lines.append([{"tag": "text", "text": f"\nğŸ’  {cat_name}"}])
            
            for item in items:
                name = item.get('name', 'æœªçŸ¥')
                close = item.get('close', 0)
                
                # --- ğŸ¯ ä¿®å¤ï¼šæ™ºèƒ½è·å–æ¶¨è·Œå¹… ---
                # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„å­—æ®µåä¸­è·å–æ¶¨è·Œå¹…æ•°æ®
                chg = item.get('chg_pct') or item.get('pct_chg') or item.get('change') or 0
                
                # è½¬åŒ–æˆæ•°å­—ï¼Œé˜²æ­¢æ˜¯å­—ç¬¦ä¸²
                try:
                    chg_val = float(chg)
                except:
                    chg_val = 0.0

                # --- ğŸ¯ ä¿®å¤ï¼šç®­å¤´é€»è¾‘ ---
                if chg_val > 0:
                    icon = "ğŸ”º" # æ¶¨ï¼šçº¢å‘ä¸Š
                    color_text = f"+{chg_val:.2f}%"
                elif chg_val < 0:
                    icon = "ğŸ”»" # è·Œï¼šç»¿å‘ä¸‹
                    color_text = f"{chg_val:.2f}%"
                else:
                    icon = "ğŸ”¹"
                    color_text = "0.00%"

                content_lines.append([{"tag": "text", "text": f"  â€¢ {name}: {close} ({icon} {color_text})"}])

        # 3. æ„å»ºé£ä¹¦å¡ç‰‡
        payload = {
            "msg_type": "post",
            "content": {
                "post": {
                    "zh_cn": {
                        "title": f"ğŸ“ˆ MarketRadar å¸‚åœºå¿«ç…§ ({report_data.get('meta', {}).get('generated_at', 'å®æ—¶')})",
                        "content": [
                            [{"tag": "text", "text": "ä»Šæ—¥å…³é”®è¡Œæƒ…æ‘˜è¦ï¼š"}]
                        ] + content_lines[:40] # é£ä¹¦å•æ¡æ¶ˆæ¯æœ‰é•¿åº¦é™åˆ¶
                    }
                }
            }
        }
        
        headers = {"Content-Type": "application/json"}
        response = requests.post(webhook_url, json=payload, headers=headers, timeout=10)
        return response.status_code == 200

    except Exception as e:
        print(f"âŒ é£ä¹¦æ¨é€è§£æå¼‚å¸¸: {e}")
        return False























