# selenium_core.py
# -----------------------------------------------------------------------------
# DeepSeek Finance Project - Selenium Scraper Core Logic
# -----------------------------------------------------------------------------

from concurrent.futures import ThreadPoolExecutor, as_completed
from selenium.webdriver.chrome.options import Options
import selenium_scrapers_investing
import selenium_scrapers_misc

class MacroDataScraper:
    def __init__(self):
        # ç›®æ ‡æ•°æ®æºé…ç½®
        self.targets = {
            "ä¸­å›½_CPI": "https://data.eastmoney.com/cjsj/cpi.html",
            "ä¸­å›½_PMI": "https://data.eastmoney.com/cjsj/pmi.html",
            "ä¸­å›½_PPI": "https://data.eastmoney.com/cjsj/ppi.html",
            "ä¸­å›½_è´§å¸ä¾›åº”é‡": "https://data.eastmoney.com/cjsj/hbgyl.html",
            "ä¸­å›½_LPR": "https://data.eastmoney.com/cjsj/globalRateLPR.html",
            "ç¾å›½_ISMåˆ¶é€ ä¸šPMI": "https://data.eastmoney.com/cjsj/foreign_0_0.html",
            "ç¾å›½_ISMéåˆ¶é€ ä¸šæŒ‡æ•°": "https://data.eastmoney.com/cjsj/foreign_0_1.html",
            "ç¾å›½_éå†œå°±ä¸š": "https://data.eastmoney.com/cjsj/foreign_0_2.html",
            "ç¾å›½_æ ¸å¿ƒé›¶å”®é”€å”®æœˆç‡": "https://data.eastmoney.com/cjsj/foreign_0_9.html",
            "ç¾å›½_åˆ©ç‡å†³è®®": "https://data.eastmoney.com/cjsj/foreign_8_0.html",
            "æ—¥æœ¬_å¤®è¡Œåˆ©ç‡å†³è®®": "https://data.eastmoney.com/cjsj/foreign_3_0.html",
            "æ’ç”ŸåŒ»ç–—ä¿å¥æŒ‡æ•°": "https://cn.investing.com/indices/hang-seng-healthcare-historical-data",
            "CNN_FearGreed": "https://edition.cnn.com/markets/fear-and-greed",
            "CBOE_PutCallRatio": "https://www.cboe.com/us/options/market_statistics/daily/",
            "Fed_Rate_Monitor": "https://www.investing.com/central-banks/fed-rate-monitor",
            "CCFI_è¿ä»·æŒ‡æ•°": "https://www.sse.net.cn/index/singleIndex?indexType=ccfi",
            "BDI_æ³¢ç½—çš„æµ·æŒ‡æ•°": "https://www.investing.com/indices/baltic-dry-historical-data",
            "USA_Initial_Jobless": "https://www.investing.com/economic-calendar/initial-jobless-claims-294",
            "CBOE_SKEW": "https://www.investing.com/indices/cboe-skew-historical-data",
            "Insider_BuySell_Ratio_USA": "https://www.gurufocus.com/economic_indicators/4359/insider-buysell-ratio-usa-overall-market",
            "USA_ISM_New_Orders": "https://www.investing.com/economic-calendar/ism-manufacturing-new-orders-index-1483"
        }

        self.key_mapping = {
            "ä¸­å›½_CPI": ("china", "CPI"),
            "ä¸­å›½_PMI": ("china", "PMI_åˆ¶é€ ä¸š"),
            "ä¸­å›½_PPI": ("china", "PPI"),
            "ä¸­å›½_è´§å¸ä¾›åº”é‡": ("china", "è´§å¸ä¾›åº”é‡"),
            "ä¸­å›½_LPR": ("china", "LPR"),
            "ç¾å›½_ISMåˆ¶é€ ä¸šPMI": ("usa", "ISM_åˆ¶é€ ä¸šPMI"),
            "ç¾å›½_ISMéåˆ¶é€ ä¸šæŒ‡æ•°": ("usa", "ISM_éåˆ¶é€ ä¸šPMI"),
            "ç¾å›½_éå†œå°±ä¸š": ("usa", "éå†œå°±ä¸šäººæ•°"),
            "ç¾å›½_æ ¸å¿ƒé›¶å”®é”€å”®æœˆç‡": ("usa", "é›¶å”®é”€å”®æœˆç‡"),
            "ç¾å›½_åˆ©ç‡å†³è®®": ("usa", "åˆ©ç‡å†³è®®"),
            "æ—¥æœ¬_å¤®è¡Œåˆ©ç‡å†³è®®": ("japan", "å¤®è¡Œåˆ©ç‡"),
            "æ’ç”ŸåŒ»ç–—ä¿å¥æŒ‡æ•°": ("hk", "æ’ç”ŸåŒ»ç–—ä¿å¥æŒ‡æ•°"),
            "CNN_FearGreed": ("market_fx", "CNN_FearGreed"),
            "CBOE_PutCallRatio": ("market_fx", "CBOE_PutCallRatio"),
            "Fed_Rate_Monitor": ("usa", "Fed_Rate_Monitor"),
            "CCFI_è¿ä»·æŒ‡æ•°": ("china", "CCFI_è¿ä»·æŒ‡æ•°"),
            "BDI_æ³¢ç½—çš„æµ·æŒ‡æ•°": ("market_fx", "BDI_æ³¢ç½—çš„æµ·æŒ‡æ•°"),
            "USA_Initial_Jobless": ("usa", "Initial_Jobless_Claims"),
            "CBOE_SKEW": ("market_fx", "CBOE_SKEW"),
            "Insider_BuySell_Ratio_USA": ("usa", "Insider_BuySell_Ratio"),
            "USA_ISM_New_Orders": ("usa", "ISM_Manufacturing_New_Orders")
        }
        
        self.results = {}
        self.status_logs = []
        
        self.chrome_options = Options()
        self.chrome_options.add_argument("--headless")
        self.chrome_options.add_argument("--disable-gpu")
        self.chrome_options.add_argument("--log-level=3")
        self.chrome_options.add_argument("--no-sandbox")
        self.chrome_options.add_argument("--disable-dev-shm-usage")
        self.chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        self.chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36')
        self.chrome_options.page_load_strategy = 'eager'
        prefs = {"profile.managed_default_content_settings.images": 2}
        self.chrome_options.add_experimental_option("prefs", prefs)
        
        self.output_path = "OnlineReport.json"

    def fetch_single_source(self, name, url):
        """
        è°ƒåº¦å™¨ï¼šæ ¹æ® name åˆ†å‘åˆ°å…·ä½“çš„ scraper å‡½æ•°
        """
        # 1. Investing.com å¸¸è§„å†å²æ•°æ®
        if name == "æ’ç”ŸåŒ»ç–—ä¿å¥æŒ‡æ•°":
            return selenium_scrapers_investing.fetch_investing_source(name, url, self.chrome_options)
        
        # Investing.com è¿‘ 10 å¤©æ•°æ®ç»„
        if name in ["BDI_æ³¢ç½—çš„æµ·æŒ‡æ•°", "CBOE_SKEW"]:
            return selenium_scrapers_investing.fetch_investing_source(name, url, self.chrome_options, days_to_keep=10)

        # 2. Investing.com è´¢ç»æ—¥å†æ•°æ®
        if name == "USA_Initial_Jobless":
            return selenium_scrapers_investing.fetch_investing_economic_calendar(name, url, self.chrome_options, days_to_keep=150)
        
        if name == "USA_ISM_New_Orders":
            return selenium_scrapers_investing.fetch_investing_economic_calendar(name, url, self.chrome_options, days_to_keep=365)
        
        if name == "Fed_Rate_Monitor":
            return selenium_scrapers_investing.fetch_fed_rate_monitor(name, url, self.chrome_options)

        # 3. ä¸“ç”¨æŠ“å–é€»è¾‘ (å…¶ä»–æ¥æº)
        if name == "CNN_FearGreed":
            return selenium_scrapers_misc.fetch_cnn_fear_greed(name, url, self.chrome_options)
            
        if name == "CBOE_PutCallRatio":
            return selenium_scrapers_misc.fetch_cboe_data(name, url, self.chrome_options)
            
        if name == "CCFI_è¿ä»·æŒ‡æ•°":
            return selenium_scrapers_misc.fetch_ccfi_data(name, url, self.chrome_options)
            
        if name == "Insider_BuySell_Ratio_USA":
            return selenium_scrapers_misc.fetch_gurufocus_insider_ratio(name, url, self.chrome_options)

        # 4. é»˜è®¤é€šç”¨æŠ“å– (Eastmoney ç­‰)
        days_to_keep = 30 if "å—å‘èµ„é‡‘" in name else 180
        return selenium_scrapers_misc.fetch_generic_source(name, url, self.chrome_options, days_to_keep)

    def run_concurrent(self):
        print("ğŸš€ [Scraper] æ­£åœ¨å¹¶å‘æŠ“å–å®è§‚æ•°æ® (Workers=2)...")
        self.status_logs = []
        
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_to_name = {
                executor.submit(self.fetch_single_source, name, url): name 
                for name, url in self.targets.items()
            }
            for future in as_completed(future_to_name):
                name, data, error_msg = future.result()
                if not error_msg:
                    self.results[name] = data
                    self.status_logs.append({'name': name, 'status': True, 'error': None})
                else:
                    self.results[name] = []
                    self.status_logs.append({'name': name, 'status': False, 'error': error_msg})
                    
        return self.results, self.status_logs

    def organize_data(self):
        nested_data = {
            "china": {},
            "usa": {},
            "japan": {},
            "hk": {},
            "market_fx": {}
        }
        
        for old_key, data_list in self.results.items():
            if not data_list:
                continue
            if old_key in self.key_mapping:
                country_key, metric_key = self.key_mapping[old_key]
                if country_key not in nested_data:
                    nested_data[country_key] = {}
                nested_data[country_key][metric_key] = data_list
        
        return nested_data

    def get_data_dict(self):
        self.run_concurrent()
        return self.organize_data(), self.status_logs