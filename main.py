import json
import os
import time
import math
import pandas as pd
from datetime import datetime

# å¼•å…¥æ¥å£
import fetch_data
import MarketRadar
# import utils # main.py ä¸å†ç›´æ¥ä¾èµ– utils è®¡ç®—ï¼Œå› ä¸º MarketRadar å·²ç»ç®—å¥½äº†

# è¾“å‡ºæ–‡ä»¶åç§°
OUTPUT_FILENAME = "MarketRadar_Report.json"

def print_banner():
    print(r"""
  __  __            _        _   ____          _            
 |  \/  | __ _ _ __| | _____| |_|  _ \ __ _ __| | __ _ _ __ 
 | |\/| |/ _` | '__| |/ / _ \ __| |_) / _` / _` |/ _` | '__|
 | |  | | (_| | |  |   <  __/ |_|  _ < (_| (_| | (_| | |   
 |_|  |_|\__,_|_|  |_|\_\___|\__|_| \_\__,_\__,_|\__,_|_|   
                                                            
    """)

def clean_and_round(data):
    """
    æ•°æ®æ¸…æ´—æ ¸å¿ƒé€»è¾‘ï¼š
    1. é€’å½’éå†å­—å…¸å’Œåˆ—è¡¨
    2. æµ®ç‚¹æ•°å¼ºåˆ¶ä¿ç•™2ä½å°æ•°
    3. å¤„ç†ç‰¹æ®Šæ•°å€¼ (NaN/Inf -> None)
    """
    if isinstance(data, dict):
        return {k: clean_and_round(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [clean_and_round(x) for x in data]
    elif isinstance(data, float):
        # æ£€æŸ¥ NaN æˆ– Infï¼Œè½¬æ¢ä¸º None (JSON null)
        if math.isnan(data) or math.isinf(data):
            return None
        return round(data, 2)
    else:
        # å…¶ä»–ç±»å‹ (int, str, None) åŸæ ·è¿”å›
        return data

def merge_data(macro_data, kline_data_dict, ma_data_list):
    """
    åˆå¹¶å®è§‚æ•°æ®ã€Kçº¿æ•°æ®å’Œå‡çº¿æ•°æ®
    """
    merged = {
        "meta": kline_data_dict.get("meta", {}),
        "æŠ€æœ¯åˆ†æ": {
            "å‘¨Kçº¿ç§»åŠ¨å¹³å‡çº¿": ma_data_list # ç›´æ¥ä½¿ç”¨ MarketRadar ä¼ å›çš„å‡çº¿æ•°æ®
        },
        # å®è§‚æ•°æ®éƒ¨åˆ†
        "market_fx": macro_data.get("market_fx", {}),
        "china": macro_data.get("china", {}),
        "usa": macro_data.get("usa", {}),
        "japan": macro_data.get("japan", {}),
        # Kçº¿æ•°æ®éƒ¨åˆ† (MarketRadaråŸæœ¬æ”¾åœ¨ "data" é”®ä¸‹)
        "market_klines": kline_data_dict.get("data", {})
    }
    
    # æ›´æ–° meta ä¿¡æ¯
    merged["meta"]["generated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    merged["meta"]["description"] = "MarketRadar Consolidated Report (Macro + Klines + MA)"
    
    return merged

def save_compact_json(data, filename):
    """
    è‡ªå®šä¹‰ JSON ä¿å­˜å‡½æ•°
    åŠŸèƒ½ï¼šå¼ºåˆ¶å°†åˆ—è¡¨å†…çš„å­—å…¸å¯¹è±¡ä¿æŒåœ¨åŒä¸€è¡Œï¼Œå®ç°ç´§å‡‘æ ¼å¼ã€‚
    """
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write('{\n')
            
            # é¡¶å±‚é”® (å¦‚ meta, market_fx, china, market_klines, æŠ€æœ¯åˆ†æ ç­‰)
            keys = list(data.keys())
            for i, key in enumerate(keys):
                val = data[key]
                
                # å†™å…¥ Key
                f.write(f'    "{key}": ')
                
                if isinstance(val, dict):
                    f.write('{\n')
                    sub_keys = list(val.keys())
                    for j, sub_key in enumerate(sub_keys):
                        sub_val = val[sub_key]
                        f.write(f'        "{sub_key}": ')
                        
                        if isinstance(sub_val, list):
                            # === æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœæ˜¯åˆ—è¡¨ï¼Œå¼ºåˆ¶å†…éƒ¨å…ƒç´ å•è¡Œæ˜¾ç¤º ===
                            f.write('[\n')
                            for k, item in enumerate(sub_val):
                                # ä½¿ç”¨ json.dumps å°†å•ä¸ªå­—å…¸è½¬ä¸ºå•è¡Œå­—ç¬¦ä¸²
                                item_str = json.dumps(item, ensure_ascii=False)
                                comma = "," if k < len(sub_val) - 1 else ""
                                f.write(f'            {item_str}{comma}\n')
                            f.write('        ]')
                        else:
                            # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼ˆä¾‹å¦‚ meta ä¸­çš„å­—ç¬¦ä¸²å€¼ï¼‰ï¼Œæ­£å¸¸ dump
                            f.write(json.dumps(sub_val, ensure_ascii=False))
                        
                        # å¤„ç†å­é¡¹ä¹‹é—´çš„é€—å·
                        if j < len(sub_keys) - 1:
                            f.write(',\n')
                        else:
                            f.write('\n')
                    f.write('    }')
                else:
                    # å¦‚æœé¡¶å±‚å€¼ä¸æ˜¯å­—å…¸ï¼Œç›´æ¥ dump
                    f.write(json.dumps(val, ensure_ascii=False))
                
                # å¤„ç†é¡¶å±‚é¡¹ä¹‹é—´çš„é€—å·
                if i < len(keys) - 1:
                    f.write(',\n')
                else:
                    f.write('\n')
            
            f.write('}')
            
        print(f"\nâœ… æˆåŠŸ! æ‰€æœ‰æ•°æ®å·²åˆå¹¶å†™å…¥ {filename} (ç´§å‡‘æ ¼å¼)")
        return True
    except Exception as e:
        print(f"\nâŒ å†™å…¥åˆå¹¶ JSON å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    start_time = time.time()
    print_banner()
    print("ğŸš€ MarketRadar å¯åŠ¨ä¸»ç¨‹åº...")
    
    # 1. è·å–å®è§‚ç»æµæ•°æ® (fetch_data)
    print("\n[Step 1/4] å¼€å§‹è·å–å®è§‚ç»æµæ•°æ®...")
    try:
        macro_data = fetch_data.get_data_main()
    except Exception as e:
        print(f"âŒ è·å–å®è§‚æ•°æ®å¤±è´¥: {e}")
        macro_data = {}

    # 2. è·å–å¸‚åœºKçº¿æ•°æ® & å‡çº¿æ•°æ® (MarketRadar)
    print("\n[Step 2/4] å¼€å§‹è·å–å…¨çƒå¸‚åœºKçº¿æ•°æ® & è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
    try:
        # MarketRadar.get_all_kline_data ç°åœ¨è¿”å›åŒ…å« "data" å’Œ "ma_data" çš„å­—å…¸
        kline_result = MarketRadar.get_all_kline_data()
        
        # æå– Kçº¿æ•°æ® (å­—å…¸: {æŒ‡æ•°:[], æ’ç”Ÿç§‘æŠ€:[]...})
        kline_data_dict = {"meta": kline_result.get("meta"), "data": kline_result.get("data")}
        
        # æå– å‡çº¿æ•°æ® (åˆ—è¡¨: [{}, {}...])
        ma_data_list = kline_result.get("ma_data", [])
        
        print(f"âœ… è·å–åˆ° {len(ma_data_list)} æ¡å‡çº¿æ•°æ®")
        
    except Exception as e:
        print(f"âŒ è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
        kline_data_dict = {"meta": {}, "data": {}}
        ma_data_list = []

    # 3. (åŸæ­¥éª¤3å·²åˆå¹¶è‡³ Step 2ï¼Œæ­¤å¤„ç•¥è¿‡)
    print("\n[Step 3/4] (å·²åœ¨ Step 2 ä¸­å¹¶å‘å®Œæˆ)")

    # 4. æ•´åˆæ•°æ®
    print("\n[Step 4/4] æ•´åˆæ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š...")
    final_data = merge_data(macro_data, kline_data_dict, ma_data_list)
    
    # === æ–°å¢ï¼šå…¨å±€æ•°æ®æ¸…æ´— (ä¿ç•™ä¸¤ä½å°æ•°) ===
    print("ğŸ§¹ [Step 4.5] æ‰§è¡Œå…¨å±€æ•°æ®æ¸…æ´— (ä¿ç•™ä¸¤ä½å°æ•°, å»é™¤NaN)...")
    final_data = clean_and_round(final_data)

    # 5. ä¿å­˜å¹¶å‘é€
    if save_compact_json(final_data, OUTPUT_FILENAME):
        # å‘é€é‚®ä»¶ (è°ƒç”¨ MarketRadar çš„é‚®ä»¶åŠŸèƒ½)
        email_subject = f"MarketRadarå…¨é‡æ—¥æŠ¥_{datetime.now().strftime('%Y-%m-%d')}"
        email_body = f"""
        MarketRadar è‡ªåŠ¨åŒ–æŠ¥å‘Š
        
        ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        åŒ…å«æ¨¡å—:
        - å®è§‚ç»æµæ•°æ® (ä¸­å›½/ç¾å›½/æ—¥æœ¬/FX)
        - å…¨çƒå¸‚åœºKçº¿ (æŒ‡æ•°/ç¾è‚¡/æ¸¯è‚¡/æ–°å…´å¸‚åœº)
        - æŠ€æœ¯åˆ†æ (ç§»åŠ¨å¹³å‡çº¿)
        
        é™„ä»¶: {OUTPUT_FILENAME}
        
        System: GitHub Actions / Local
        """
        MarketRadar.send_email(email_subject, email_body, [OUTPUT_FILENAME])

    elapsed = time.time() - start_time
    print(f"\nâœ¨ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f} ç§’")

if __name__ == "__main__":
    main()